# ollama\u7531\u4E8E\u662F\u672C\u5730\u5B89\u88C5\u542F\u52A8\u7684\uFF0C\u6240\u4EE5baseUrl\u4E3A\u672C\u5730\u5730\u5740\u6216\u8005\u8FDC\u7A0B\u67D0\u53F0\u673A\u5668\uFF0C\u7AEF\u53E3\u9ED8\u8BA4\u4E3A11434
# \u53C2\u8003\u6587\u6863\uFF1Ahttps://ollama.com/
langchain4j.ollama.chat-model.base-url=http://localhost:11434
# \u6A21\u578B\u540D\u79F0
langchain4j.ollama.chat-model.model-name=llama3.1
# \u5176\u4ED6\u53C2\u6570\uFF0C\u53C2\u8003\u6587\u6863https://docs.langchain4j.dev/integrations/language-models/ollama
# temperature\u8868\u793A\u968F\u673A\u6027\uFF0C\u503C\u8D8A\u5927\uFF0C\u968F\u673A\u6027\u8D8A\u5927\uFF0C\u8D8A\u968F\u673A\uFF0C\u53CD\u4E4B\u8D8A\u7CBE\u786E
langchain4j.ollama.chat-model.temperature=0.8
# \u8D85\u65F6\u65F6\u95F4\uFF0C\u9ED8\u8BA460\u79D2
langchain4j.ollama.chat-model.timeout=PT60S
# \u91CD\u8BD5\u6B21\u6570
langchain4j.ollama.chat-model.max-retries=3
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true
# \u5982\u679C\u9700\u8981\u770B\u8BE6\u7EC6\u65E5\u5FD7\uFF0C\u8BF7\u5C06\u6B64\u503C\u8BBE\u7F6E\u4E3Adebug
logging.level.root=debug